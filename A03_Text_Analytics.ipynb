{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f5372fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2989ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk import bigrams\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17212bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9802a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Israel_Palestine_Public_Opinion_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a8235",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Reducing Dataset Size](#Reducing-Dataset-Size)\n",
    "2. [Data Cleaning](#Data-Cleaning)\n",
    "   1. [Dropping Irrelevant Features](#Dropping-irrelevant-features)\n",
    "   2. [Dealing with Missing Values](#Dealing-with-missing-values)\n",
    "   3. [Dealing with Duplicate Values](#Dealing-with-duplicate-values)\n",
    "   4. [Understanding the Data](#Understanding-the-data)\n",
    "3. [Data Preparation](#Data-Preparation)\n",
    "   1. [Making all Text Lowercase](#Making-all-text-Lowercase)\n",
    "   2. [Removing Irrelevant Characters](#Removing-Irrelevant-Characters)\n",
    "   3. [Tokenising](#Tokenising)\n",
    "   4. [Removing Stopwords](#Removing-Stopwords)\n",
    "   5. [Lemmatization](#Lemmatization)\n",
    "   6. [Joining & Finishing Up](#Joining-&-Finishing-Up)\n",
    "4. [EDA](#EDA)\n",
    "   1. [Most Common Words](#Most-Common-Words)\n",
    "   2. [Word Cloud](#Word-Cloud)\n",
    "   3. [Comment Length](#Comment-Length)\n",
    "       1. [Removing Long Comments](#Removing-Long-Comments)\n",
    "5. [Sentiment Analysis (Lexicon-Based)](#Sentiment-Analysis-(lexicon-based))\n",
    "6. [Feature Extraction](#Feature-Extraction)\n",
    "7. [Sentiment Prediction](#Sentiment-Prediction)\n",
    "8. [Topic Modeling: LDA](#Topic-Modeling:-LDA)\n",
    "9. [Supervised Model](#Supervised-Model)\n",
    "10. [Downloading Dataset for Dashboard](#Downloading-Dataset-for-Dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa616071",
   "metadata": {},
   "source": [
    "# Reducing Dataset Size\n",
    "The computational cost of 75000 comments is far to great to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7579da36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75543, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f453a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c480c",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d8162e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18886, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5aa6997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59569</th>\n",
       "      <td>k85pcsy</td>\n",
       "      <td>236</td>\n",
       "      <td>It’s not that they forgot, it’s that they don’...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2023-11-07 02:02:41+00:00</td>\n",
       "      <td>2023-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14965</th>\n",
       "      <td>k4vm5nc</td>\n",
       "      <td>1</td>\n",
       "      <td>Lmao they are downvoting you \\n\\nWhat a sub</td>\n",
       "      <td>AskMiddleEast</td>\n",
       "      <td>2023-10-14 18:53:27+00:00</td>\n",
       "      <td>2023-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73868</th>\n",
       "      <td>k9g6mku</td>\n",
       "      <td>18</td>\n",
       "      <td>That's when the heavy hand of the IDF comes in...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2023-11-16 02:38:30+00:00</td>\n",
       "      <td>2023-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40909</th>\n",
       "      <td>k6skwta</td>\n",
       "      <td>2</td>\n",
       "      <td>I mean, is there one?\\nIts all interconnected ...</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>2023-10-28 08:09:45+00:00</td>\n",
       "      <td>2023-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>k3uafz0</td>\n",
       "      <td>3</td>\n",
       "      <td>If this is your response to civilians getting ...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-10-07 11:45:45+00:00</td>\n",
       "      <td>2023-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46101</th>\n",
       "      <td>k79l2ag</td>\n",
       "      <td>2</td>\n",
       "      <td>They’re killing a population made up of mostly...</td>\n",
       "      <td>PublicFreakout</td>\n",
       "      <td>2023-10-31 18:54:34+00:00</td>\n",
       "      <td>2023-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22577</th>\n",
       "      <td>k5e24k4</td>\n",
       "      <td>5</td>\n",
       "      <td>Here is a sound comparison between the differe...</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>2023-10-18 11:51:54+00:00</td>\n",
       "      <td>2023-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73251</th>\n",
       "      <td>k9jgpw0</td>\n",
       "      <td>-3</td>\n",
       "      <td>To kill civilians.\\n\\nIt's always been the pla...</td>\n",
       "      <td>IsrealPalestineWar_23</td>\n",
       "      <td>2023-11-16 19:19:08+00:00</td>\n",
       "      <td>2023-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21050</th>\n",
       "      <td>k5706ih</td>\n",
       "      <td>1</td>\n",
       "      <td>Diaspora Palestinian here.  I have visited my ...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-10-17 00:38:38+00:00</td>\n",
       "      <td>2023-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74522</th>\n",
       "      <td>k9m2lhp</td>\n",
       "      <td>9</td>\n",
       "      <td>lol clearly failed at school. What clowns. Can...</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>2023-11-17 07:46:08+00:00</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id  score                                          self_text  \\\n",
       "59569    k85pcsy    236  It’s not that they forgot, it’s that they don’...   \n",
       "14965    k4vm5nc      1        Lmao they are downvoting you \\n\\nWhat a sub   \n",
       "73868    k9g6mku     18  That's when the heavy hand of the IDF comes in...   \n",
       "40909    k6skwta      2  I mean, is there one?\\nIts all interconnected ...   \n",
       "1096     k3uafz0      3  If this is your response to civilians getting ...   \n",
       "46101    k79l2ag      2  They’re killing a population made up of mostly...   \n",
       "22577    k5e24k4      5  Here is a sound comparison between the differe...   \n",
       "73251    k9jgpw0     -3  To kill civilians.\\n\\nIt's always been the pla...   \n",
       "21050    k5706ih      1  Diaspora Palestinian here.  I have visited my ...   \n",
       "74522    k9m2lhp      9  lol clearly failed at school. What clowns. Can...   \n",
       "\n",
       "                   subreddit               created_time created_date  \n",
       "59569              worldnews  2023-11-07 02:02:41+00:00   2023-11-07  \n",
       "14965          AskMiddleEast  2023-10-14 18:53:27+00:00   2023-10-14  \n",
       "73868              worldnews  2023-11-16 02:38:30+00:00   2023-11-16  \n",
       "40909              Palestine  2023-10-28 08:09:45+00:00   2023-10-28  \n",
       "1096           CombatFootage  2023-10-07 11:45:45+00:00   2023-10-07  \n",
       "46101         PublicFreakout  2023-10-31 18:54:34+00:00   2023-10-31  \n",
       "22577              Palestine  2023-10-18 11:51:54+00:00   2023-10-18  \n",
       "73251  IsrealPalestineWar_23  2023-11-16 19:19:08+00:00   2023-11-16  \n",
       "21050        IsraelPalestine  2023-10-17 00:38:38+00:00   2023-10-17  \n",
       "74522              Palestine  2023-11-17 07:46:08+00:00   2023-11-17  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceba958b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>k3w6ooy</td>\n",
       "      <td>5</td>\n",
       "      <td>Just rid the nation of hamas like they did wit...</td>\n",
       "      <td>PublicFreakout</td>\n",
       "      <td>2023-10-07 19:39:37+00:00</td>\n",
       "      <td>2023-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36692</th>\n",
       "      <td>k6fgkac</td>\n",
       "      <td>5</td>\n",
       "      <td>He is not Turkish just a wannabe.</td>\n",
       "      <td>AskMiddleEast</td>\n",
       "      <td>2023-10-25 18:31:43+00:00</td>\n",
       "      <td>2023-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20566</th>\n",
       "      <td>k5bfi4v</td>\n",
       "      <td>7</td>\n",
       "      <td>Peak noncredibility</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-10-17 21:36:15+00:00</td>\n",
       "      <td>2023-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>k3tx7ln</td>\n",
       "      <td>58</td>\n",
       "      <td>1. jewish holiday\\n2. Yom-Kippur 50 year anive...</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>2023-10-07 09:00:57+00:00</td>\n",
       "      <td>2023-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9628</th>\n",
       "      <td>k4lh56u</td>\n",
       "      <td>1</td>\n",
       "      <td>They have confirmed in the last 2 hours. That ...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-10-12 18:25:14+00:00</td>\n",
       "      <td>2023-10-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id  score                                          self_text  \\\n",
       "236      k3w6ooy      5  Just rid the nation of hamas like they did wit...   \n",
       "36692    k6fgkac      5                  He is not Turkish just a wannabe.   \n",
       "20566    k5bfi4v      7                                Peak noncredibility   \n",
       "593      k3tx7ln     58  1. jewish holiday\\n2. Yom-Kippur 50 year anive...   \n",
       "9628     k4lh56u      1  They have confirmed in the last 2 hours. That ...   \n",
       "\n",
       "                subreddit               created_time created_date  \n",
       "236        PublicFreakout  2023-10-07 19:39:37+00:00   2023-10-07  \n",
       "36692       AskMiddleEast  2023-10-25 18:31:43+00:00   2023-10-25  \n",
       "20566  NonCredibleDefense  2023-10-17 21:36:15+00:00   2023-10-17  \n",
       "593             Palestine  2023-10-07 09:00:57+00:00   2023-10-07  \n",
       "9628      IsraelPalestine  2023-10-12 18:25:14+00:00   2023-10-12  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f4c5af",
   "metadata": {},
   "source": [
    "## Dropping irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5511bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['created_time', 'created_date', 'subreddit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab6fc98",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd870862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_id    0\n",
       "score         0\n",
       "self_text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c47e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['self_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15f0b3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_id    0\n",
       "score         0\n",
       "self_text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710921f3",
   "metadata": {},
   "source": [
    "## Dealing with duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a32a31e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbee0978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18886, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71710c6",
   "metadata": {},
   "source": [
    "## Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c84ffd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_id    object\n",
       "score          int64\n",
       "self_text     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe2aede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.610717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>147.226880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5531.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "count  18886.000000\n",
       "mean      23.610717\n",
       "std      147.226880\n",
       "min     -781.000000\n",
       "25%        1.000000\n",
       "50%        2.000000\n",
       "75%        8.000000\n",
       "max     5531.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e9a47",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e6d6f",
   "metadata": {},
   "source": [
    "## Making all text Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7fa4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['self_text'] = df['self_text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b03fe2",
   "metadata": {},
   "source": [
    "## Removing Irrelevant Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53430114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['self_text'] = df['self_text'].str.replace(r'http\\S+|www\\S+|https\\S+', ' ', regex=True)\n",
    "df['self_text'] = df['self_text'].str.replace(r\"\\d+\", \" \", regex=True)\n",
    "df['self_text'] = df['self_text'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "# (Jerry, 2014)(DataScientYst - Data Science Simplified, 2021)(Python, 2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bccfb",
   "metadata": {},
   "source": [
    "## Tokenising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e25eb05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['self_text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689eefe",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5afa4393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7beed372",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "spacy_stopwords = nlp.Defaults.stop_words\n",
    "additional_stopwords = {'do', 'like', \"s\", \"m\", \"re\", 'l', 'i', 'I', 'they', 'now'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d244d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stopwords = set([word.lower() for word in nltk_stopwords.union(spacy_stopwords).union(additional_stopwords)])\n",
    "# print(combined_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39dd03ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filtered_tokens'] = df['tokens'].apply(lambda x: [word.lower() for word in x if word.lower() not in combined_stopwords and (len(word) > 1 or word.lower() in ('a', 'i'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef3425",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "(ame, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ec5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_text(tokens):\n",
    "    doc = nlp(' '.join(tokens))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "df['lemmatized'] = df['filtered_tokens'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0fa6b",
   "metadata": {},
   "source": [
    "## Joining & Finishing Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bac563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_wx'] = df['lemmatized'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['text_wx'].astype(str))\n",
    "    # putting all the comments into one string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d867515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['tokens', 'filtered_tokens', 'lemmatized'])\n",
    "df = df[['comment_id', 'score', 'text_wx']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd02ba1",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1565903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db408",
   "metadata": {},
   "source": [
    "## Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4433cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for text in df['text_wx'] for word in text.split()]\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "most_common_words = word_counts.most_common(30)\n",
    "words, counts = zip(*most_common_words)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(words, counts)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 10 Most Common Words')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b18a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_words = [word for text in df['text_wx'] for word in text.split()]\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "most_common_words = word_counts.most_common(40)\n",
    "words, counts = zip(*most_common_words)\n",
    "\n",
    "plt.figure(figsize=(50, 10))\n",
    "plt.bar(words, counts)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 10 Most Common Words')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b240501c",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d487462",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                      background_color ='black', \n",
    "                      min_font_size = 10).generate(text)\n",
    "\n",
    "plt.figure(figsize = (10, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "plt.show()\n",
    "\n",
    "(DataCamp, n.d.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605626e8",
   "metadata": {},
   "source": [
    "## Comment Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_length'] = df['text_wx'].str.len()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(df['comment_length'], vert=False)\n",
    "plt.title('Box Plot of Comment Lengths')\n",
    "plt.xlabel('Length of Comment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddbe848",
   "metadata": {},
   "source": [
    "### Removing Long Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['comment_length'] <= 1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b78279",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(df['comment_length'], vert=False)\n",
    "plt.title('Box Plot of Comment Lengths after Trimming')\n",
    "plt.xlabel('Length of Comment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21593273",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (lexicon-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04225b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIA = SentimentIntensityAnalyzer()\n",
    "\n",
    "df['sentiment'] = df['text_wx'].apply(lambda x: SIA.polarity_scores(x))\n",
    "\n",
    "df['sentiment_score'] = df['sentiment'].apply(lambda x: x['compound'])\n",
    "df['sentiment_label'] = df['sentiment_score'].apply(lambda c: 'positive' if c > 0.05 else ('negative' if c < -0.05 else 'neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = df['sentiment_label'].value_counts()\n",
    "\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='coolwarm')\n",
    "plt.title('Sentiment Label Distribution')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d607eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['sentiment_score'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Sentiment Scores')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81d009",
   "metadata": {},
   "source": [
    "#  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['text_wx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac976ad",
   "metadata": {},
   "source": [
    "# Sentiment Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6423f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df['sentiment_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, y_pred, test_size=0.2, random_state=42)\n",
    "    # Text Analytics - Bag of Words Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f16268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfidf = MultinomialNB()\n",
    "model_tfidf.fit(X_train, y_train)\n",
    "sentiment_pred = model_tfidf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5dfa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_tfidf = classification_report(y_test, sentiment_pred, output_dict=True)\n",
    "\n",
    "accuracy = report_tfidf['accuracy']\n",
    "macro_avg = report_tfidf['macro avg']\n",
    "weighted_avg = report_tfidf['weighted avg']\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Macro Avg Precision: {macro_avg['precision']:.2f}, Recall: {macro_avg['recall']:.2f}, F1-score: {macro_avg['f1-score']:.2f}\")\n",
    "print(f\"Weighted Avg Precision: {weighted_avg['precision']:.2f}, Recall: {weighted_avg['recall']:.2f}, F1-score: {weighted_avg['f1-score']:.2f}\")\n",
    "\n",
    "    # print(report_tfidf) couldn't print report as the output was too large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab738c27",
   "metadata": {},
   "source": [
    "# Topic Modeling: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac543f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = count_vectorizer.fit_transform(df['text_wx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d927700",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    top_words = [tf_feature_names[i] for i in topic.argsort()[-30:]]\n",
    "    top_words.reverse() # Reversing order so that most important is shown first\n",
    "    print(\" \".join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430957bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = lda_model.transform(dtm)\n",
    "\n",
    "df['topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = {0: 'Ethics & Beliefs', 1: 'Military', 2: 'History', 3: 'Unclear Web Related', 4: 'Concern for Innocent'}\n",
    "\n",
    "df['topic_label'] = df['topic'].map(topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_label_counts = df['topic_label'].value_counts()\n",
    "print(topic_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ca2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=topic_label_counts.index, \n",
    "            y=topic_label_counts.values,\n",
    "            palette=\"viridis\")\n",
    "plt.title('Comments by Topics')\n",
    "plt.xlabel('Topic Labels')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88cf857",
   "metadata": {},
   "source": [
    "# Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60647b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['text_wx'])\n",
    "    # Same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_features  \n",
    "y = df['topic_label'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa06e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd0582",
   "metadata": {},
   "source": [
    "# Downloading Dataset for Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e335662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cde292",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/danie/Documents/Predictive Data Analytics/Israel_Palestine_conflict_project/text_analytics_dataset.csv', index=False)\n",
    "# Saving for use in Dashboard notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
